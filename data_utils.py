# -*- coding: utf-8 -*-
"""data_utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TbhOBH229y2ekuT35e_at5LWovvFYIic
"""

# ================================================
# data_utils.py
# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»ãƒ‡ãƒ¼ã‚¿æ“ä½œã®å…±é€šé–¢æ•°é›†
# ================================================

import pandas as pd
import numpy as np
import os
import logging
from typing import Optional, List, Tuple, Union
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ç³»é–¢æ•°
# ================================================

def load_csv_data(file_path: str, target_column: str, features_to_drop: Optional[List[str]] = None) -> Tuple[pd.DataFrame, pd.Series]:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ç‰¹å¾´é‡Xã¨ç›®çš„å¤‰æ•°yã«åˆ†å‰²ã™ã‚‹é–¢æ•°

    Args:
        file_path (str): CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        target_column (str): ç›®çš„å¤‰æ•°ã®ã‚«ãƒ©ãƒ å
        features_to_drop (List[str], optional): ãƒ‰ãƒ­ãƒƒãƒ—ã—ãŸã„ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ

    Returns:
        Tuple[pd.DataFrame, pd.Series]: ç‰¹å¾´é‡Xã€ç›®çš„å¤‰æ•°y
    """
    try:
        if not os.path.exists(file_path):
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")
            return None, None

        df = pd.read_csv(file_path)
        logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {file_path}")
        logger.info(f"ğŸ” ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:\n{df.describe().T}")

        if features_to_drop:
            df = df.drop(columns=features_to_drop)

        if target_column not in df.columns:
            logger.error(f"âŒ æŒ‡å®šã•ã‚ŒãŸç›®çš„å¤‰æ•° '{target_column}' ãŒãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¾ã›ã‚“")
            return None, None

        X = df.drop(columns=[target_column])
        y = df[target_column]

        return X, y

    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

# ================================================
# æ¬ æå€¤å‡¦ç†ãƒ»ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç³»é–¢æ•°
# ================================================

def fill_missing_values(X: pd.DataFrame, strategy: str = "mean") -> pd.DataFrame:
    """
    æ¬ æå€¤ã‚’è£œå®Œã™ã‚‹é–¢æ•°

    Args:
        X (pd.DataFrame): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        strategy (str, optional): è£œå®Œæ–¹æ³•ï¼ˆ"mean" ã¾ãŸã¯ "median"ï¼‰

    Returns:
        pd.DataFrame: è£œå®Œå¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    try:
        if strategy == "mean":
            X = X.fillna(X.mean())
            logger.info("âœ… æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œã—ã¾ã—ãŸ")
        elif strategy == "median":
            X = X.fillna(X.median())
            logger.info("âœ… æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œã—ã¾ã—ãŸ")
        else:
            logger.warning("âš ï¸ ç„¡åŠ¹ãªstrategyãŒæŒ‡å®šã•ã‚ŒãŸãŸã‚ã€å¹³å‡å€¤ã§è£œå®Œã—ã¾ã—ãŸ")
            X = X.fillna(X.mean())

        return X

    except Exception as e:
        logger.error(f"âŒ æ¬ æå€¤è£œå®Œã‚¨ãƒ©ãƒ¼: {e}")
        return X


def encode_categorical(X: pd.DataFrame, drop_first: bool = True) -> pd.DataFrame:
    """
    ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹é–¢æ•°

    Args:
        X (pd.DataFrame): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        drop_first (bool, optional): ãƒ€ãƒŸãƒ¼å¤‰æ•°è½ã¨ã— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆTrue)

    Returns:
        pd.DataFrame: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    try:
        cat_columns = X.select_dtypes(include=["object", "category"]).columns

        if len(cat_columns) == 0:
            logger.info("ğŸ” ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return X

        logger.info(f"ğŸ”„ ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¾ã™: {list(cat_columns)}")
        X_encoded = pd.get_dummies(X, columns=cat_columns, drop_first=drop_first)

        return X_encoded

    except Exception as e:
        logger.error(f"âŒ ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return X

# ================================================
# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ãƒ»ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç³»é–¢æ•°
# ================================================

def split_data(X: pd.DataFrame, y: pd.Series,
               test_size: float = 0.2,
               validation_size: float = 0.0,
               random_state: int = 42
               ) -> Union[
                   Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series],
                   Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, pd.Series]
               ]:
    """
    å­¦ç¿’ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã™ã‚‹é–¢æ•°

    Args:
        X (pd.DataFrame): ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿
        y (pd.Series): ç›®çš„å¤‰æ•°
        test_size (float): ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ
        validation_size (float): æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆï¼ˆ0ã®å ´åˆã¯æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
        random_state (int): ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰

    Returns:
        Tuple: åˆ†å‰²å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆå­¦ç¿’/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆï¼‰
    """
    try:
        if validation_size > 0:
            X_train, X_temp, y_train, y_temp = train_test_split(
                X, y, test_size=test_size + validation_size, random_state=random_state
            )
            valid_ratio = validation_size / (test_size + validation_size)
            X_valid, X_test, y_valid, y_test = train_test_split(
                X_temp, y_temp, test_size=1-valid_ratio, random_state=random_state
            )
            logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿3åˆ†å‰²å®Œäº† - Train:{X_train.shape}, Valid:{X_valid.shape}, Test:{X_test.shape}")
            return X_train, X_valid, X_test, y_train, y_valid, y_test
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state
            )
            logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿2åˆ†å‰²å®Œäº† - Train:{X_train.shape}, Test:{X_test.shape}")
            return X_train, X_test, y_train, y_test

    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def scale_data(X_train: pd.DataFrame,
               X_test: pd.DataFrame,
               scaler_type: str = "standard") -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’è¡Œã†é–¢æ•°

    Args:
        X_train (pd.DataFrame): å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        X_test (pd.DataFrame): ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        scaler_type (str): ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ç¨®é¡ï¼ˆ"standard" ã¾ãŸã¯ "minmax"ï¼‰

    Returns:
        Tuple[pd.DataFrame, pd.DataFrame]: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã®å­¦ç¿’ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    """
    try:
        if scaler_type == "standard":
            scaler = StandardScaler()
            logger.info("âœ… StandardScalerã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã¾ã—ãŸ")
        elif scaler_type == "minmax":
            scaler = MinMaxScaler()
            logger.info("âœ… MinMaxScalerã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã¾ã—ãŸ")
        else:
            logger.warning(f"âš ï¸ ç„¡åŠ¹ãªscaler_typeãŒæŒ‡å®šã•ã‚ŒãŸãŸã‚ã€StandardScalerã‚’ä½¿ç”¨ã—ã¾ã™")
            scaler = StandardScaler()

        X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)
        X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)

        return X_train_scaled, X_test_scaled

    except Exception as e:
        logger.error(f"âŒ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        return X_train, X_test

# ================================================
# è£œåŠ©ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ================================================

def show_data_summary(X: pd.DataFrame, y: Optional[pd.Series] = None) -> None:
    """
    ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±ï¼ˆå½¢çŠ¶ã€æ¬ æå€¤ã€çµ±è¨ˆé‡ï¼‰ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°

    Args:
        X (pd.DataFrame): ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿
        y (pd.Series, optional): ç›®çš„å¤‰æ•°ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ã‚Œã°ï¼‰
    """
    try:
        logger.info(f"ğŸ—‚ï¸ ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X.shape}")
        if y is not None:
            logger.info(f"ğŸ¯ ç›®çš„å¤‰æ•°ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {y.shape}")

        logger.info("ğŸ” ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿æ¬ æå€¤ã‚µãƒãƒªãƒ¼:")
        logger.info(f"\n{X.isnull().sum()[X.isnull().sum() > 0]}")

        logger.info("ğŸ“ˆ ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆé‡:")
        logger.info(f"\n{X.describe().T}")

    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼å‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")

