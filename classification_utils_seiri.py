# -*- coding: utf-8 -*-
"""æ•´ç†ç‰ˆ classification_utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wPzSlkrDUUU2ILGxFNpQDgKW-z-RuyhK
"""

# ================================================
# classification_utils.py
# åˆ†é¡ã‚¿ã‚¹ã‚¯ç”¨ï¼šãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»è©•ä¾¡ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ================================================

import pandas as pd
import numpy as np
import joblib
import logging
from typing import Any, Dict
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ================================================
# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
# ================================================

def train_model(X_train: pd.DataFrame, y_train: pd.Series,
                model_type: str = "xgboost",
                params: Dict = None,
                num_class: int = None) -> Any:
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’ã‚’è¡Œã†é–¢æ•°
    """
    logger.info(f"ğŸ”„ {model_type} ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹")

    if params is None:
        params = {}

    if model_type.lower() == "xgboost":
        default_params = {
            'learning_rate': 0.1,
            'max_depth': 5,
            'n_estimators': 100,
            'random_state': 42
        }
        if num_class and num_class > 2:
            default_params.update({
                'objective': 'multi:softprob',
                'num_class': num_class,
                'eval_metric': 'mlogloss'
            })
        else:
            default_params.update({
                'objective': 'binary:logistic',
                'eval_metric': 'logloss'
            })
        default_params.update(params)
        model = XGBClassifier(**default_params)

    elif model_type.lower() == "random_forest":
        default_params = {
            'n_estimators': 100,
            'max_depth': 10,
            'random_state': 42
        }
        default_params.update(params)
        model = RandomForestClassifier(**default_params)

    elif model_type.lower() == "logistic":
        default_params = {
            'C': 1.0,
            'penalty': 'l2',
            'solver': 'lbfgs',
            'max_iter': 1000,
            'random_state': 42
        }
        if num_class and num_class > 2:
            default_params['multi_class'] = 'multinomial'
        default_params.update(params)
        model = LogisticRegression(**default_params)

    elif model_type.lower() == "svm":
        default_params = {
            'C': 1.0,
            'kernel': 'rbf',
            'gamma': 'scale',
            'probability': True,
            'random_state': 42
        }
        default_params.update(params)
        model = SVC(**default_params)

    else:
        logger.error(f"âŒ æœªå¯¾å¿œã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {model_type}")
        return None

    model.fit(X_train, y_train)
    logger.info("âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
    return model

# ================================================
# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
# ================================================

def evaluate_model(model: Any, X_test: pd.DataFrame, y_test: pd.Series) -> None:
    """
    ãƒ¢ãƒ‡ãƒ«ã®Accuracyã€Classification Reportã€Confusion Matrixã‚’å‡ºåŠ›ã™ã‚‹é–¢æ•°
    """
    try:
        preds = model.predict(X_test)
        logger.info(f"âœ… Accuracy: {accuracy_score(y_test, preds):.4f}")
        logger.info("ğŸ“„ Classification Report:\n" + classification_report(y_test, preds))

        cm = confusion_matrix(y_test, preds)
        logger.info("ğŸ“Š Confusion Matrix:")
        logger.info(f"\n{cm}")

    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")

# ================================================
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­è¾¼
# ================================================

def save_model(model: Any, path: str) -> None:
    """
    å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°
    """
    try:
        joblib.dump(model, path)
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {path}")
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def load_model(path: str) -> Any:
    """
    ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
    """
    try:
        model = joblib.load(path)
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­è¾¼å®Œäº†: {path}")
        return model
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None