# -*- coding: utf-8 -*-
"""æ•´ç†ç‰ˆ clustering_utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xRxWkJsF0DuO_gfxheTGUklDbZ3Hu5Yt
"""

# ================================================
# clustering_utils.py
# ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ç”¨ï¼šãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»è©•ä¾¡ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ================================================

import pandas as pd
import numpy as np
import joblib
import logging
from typing import Any, Dict
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.metrics import silhouette_score

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ================================================
# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# ================================================

def train_clustering_model(X: pd.DataFrame,
                            model_type: str = "kmeans",
                            params: Dict = None) -> Any:
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’ã‚’è¡Œã†é–¢æ•°
    """
    logger.info(f"ğŸ”„ {model_type} ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å­¦ç¿’é–‹å§‹")

    if params is None:
        params = {}

    if model_type.lower() == "kmeans":
        default_params = {'n_clusters': 3, 'random_state': 42}
        default_params.update(params)
        model = KMeans(**default_params)

    elif model_type.lower() == "dbscan":
        default_params = {'eps': 0.5, 'min_samples': 5}
        default_params.update(params)
        model = DBSCAN(**default_params)

    elif model_type.lower() == "agglomerative":
        default_params = {'n_clusters': 3, 'linkage': 'ward'}
        default_params.update(params)
        model = AgglomerativeClustering(**default_params)

    else:
        logger.error(f"âŒ æœªå¯¾å¿œã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {model_type}")
        return None

    model.fit(X)
    logger.info("âœ… ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å­¦ç¿’å®Œäº†")
    return model

# ================================================
# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
# ================================================

def evaluate_clustering_model(model: Any, X: pd.DataFrame) -> None:
    """
    ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
    """
    try:
        if hasattr(model, "labels_"):
            labels = model.labels_
        else:
            labels = model.predict(X)

        score = silhouette_score(X, labels)
        logger.info(f"âœ… ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: {score:.4f}")

    except Exception as e:
        logger.error(f"âŒ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")

# ================================================
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­è¾¼
# ================================================

def save_model(model: Any, path: str) -> None:
    """
    å­¦ç¿’æ¸ˆã¿ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°
    """
    try:
        joblib.dump(model, path)
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {path}")
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def load_model(path: str) -> Any:
    """
    ä¿å­˜ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
    """
    try:
        model = joblib.load(path)
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­è¾¼å®Œäº†: {path}")
        return model
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None