# -*- coding: utf-8 -*-
"""整理版 reinforcement_learning_utils.py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m7Wa2JUphrJBOWXZ3hc63nqOrStaUh2Z
"""

# ================================================
# reinforcement_learning_utils.py
# 強化学習タスク用：学習・保存ユーティリティ関数（簡易版）
# ================================================

import gym
import joblib
import logging
from typing import Any
import numpy as np

# ログ設定
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ================================================
# 強化学習エージェントの学習
# ================================================

def train_q_learning(env_name: str = "FrozenLake-v1",
                     num_episodes: int = 1000,
                     learning_rate: float = 0.1,
                     discount_factor: float = 0.99,
                     epsilon: float = 0.1
                     ) -> Any:
    """
    Q-Learningで環境を学習するシンプルなエージェント
    """
    try:
        env = gym.make(env_name)
        n_states = env.observation_space.n
        n_actions = env.action_space.n
        Q = np.zeros((n_states, n_actions))

        for episode in range(num_episodes):
            state = env.reset()
            done = False

            while not done:
                if np.random.rand() < epsilon:
                    action = env.action_space.sample()
                else:
                    action = np.argmax(Q[state])

                next_state, reward, done, _ = env.step(action)
                best_next_action = np.argmax(Q[next_state])
                td_target = reward + discount_factor * Q[next_state][best_next_action]
                Q[state][action] += learning_rate * (td_target - Q[state][action])
                state = next_state

        logger.info(f"✅ Q-Learning学習完了（{env_name}, {num_episodes} episodes）")
        return Q

    except Exception as e:
        logger.error(f"❌ 強化学習エラー: {e}")
        return None

# ================================================
# 学習済みQテーブルの保存・読込
# ================================================

def save_q_table(Q: Any, path: str) -> None:
    """
    Qテーブルを保存
    """
    try:
        joblib.dump(Q, path)
        logger.info(f"✅ Qテーブル保存完了: {path}")
    except Exception as e:
        logger.error(f"❌ Qテーブル保存エラー: {e}")

def load_q_table(path: str) -> Any:
    """
    Qテーブルを読込
    """
    try:
        Q = joblib.load(path)
        logger.info(f"✅ Qテーブル読込完了: {path}")
        return Q
    except Exception as e:
        logger.error(f"❌ Qテーブル読込エラー: {e}")
        return None