# -*- coding: utf-8 -*-
"""anomaly_detection_utils.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KcwZl5wWLNdBOqH09QSd9oSnVmfvXcwP

1. ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ»ç’°å¢ƒè¨­å®šï¼ˆãƒ­ã‚®ãƒ³ã‚°å«ã‚€ï¼‰
2. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»å‰å‡¦ç†ï¼ˆæ¨™æº–åŒ–ãªã©ï¼‰
3. ç•°å¸¸æ¤œçŸ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é©ç”¨ï¼ˆIsolation Forest, One-Class SVMå¯¾å¿œäºˆå®šï¼‰
4. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒå¯è¦–åŒ–
5. ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­è¾¼ï¼ˆGoogle Driveå¯¾å¿œï¼‰
6. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ”¯æ´
"""

# ================================
# ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ç’°å¢ƒè¨­å®š
# ================================

import os
import joblib
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
from google.colab import drive
from google.colab import files

from typing import Any, Dict, List, Optional, Tuple, Union

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)
# ================================
# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»å‰å‡¦ç†
# ================================

def load_csv_data(file_path: str, features_to_drop: Optional[List[str]] = None) -> pd.DataFrame:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    try:
        if not os.path.exists(file_path) and '/content/drive' not in file_path:
            file_path = os.path.join('/content/drive/MyDrive/', file_path)

        df = pd.read_csv(file_path)
        logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {df.shape}")

        if features_to_drop:
            df = df.drop(columns=features_to_drop)

        return df
    except Exception as e:
        logger.error(f"âŒ CSVãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return None

def standardize_data(X: pd.DataFrame) -> pd.DataFrame:
    """ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–ã™ã‚‹"""
    try:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        logger.info("âœ… ç‰¹å¾´é‡æ¨™æº–åŒ–å®Œäº†")
        return pd.DataFrame(X_scaled, columns=X.columns)
    except Exception as e:
        logger.error(f"âŒ æ¨™æº–åŒ–å¤±æ•—: {e}")
        return None
# ================================
# ç•°å¸¸æ¤œçŸ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é©ç”¨
# ================================

def train_isolation_forest(X: pd.DataFrame, contamination: float = 0.05) -> Any:
    """Isolation Forestã§ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’"""
    try:
        model = IsolationForest(contamination=contamination, random_state=42)
        model.fit(X)
        logger.info("âœ… Isolation Forestå­¦ç¿’å®Œäº†")
        return model
    except Exception as e:
        logger.error(f"âŒ Isolation Forestå­¦ç¿’å¤±æ•—: {e}")
        return None

def train_one_class_svm(X: pd.DataFrame, nu: float = 0.05, kernel: str = 'rbf') -> Any:
    """One-Class SVMã§ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’"""
    try:
        model = OneClassSVM(nu=nu, kernel=kernel)
        model.fit(X)
        logger.info("âœ… One-Class SVMå­¦ç¿’å®Œäº†")
        return model
    except Exception as e:
        logger.error(f"âŒ One-Class SVMå­¦ç¿’å¤±æ•—: {e}")
        return None
# ================================
# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒå¯è¦–åŒ–
# ================================

def evaluate_anomaly_detection(model: Any, X: pd.DataFrame) -> pd.Series:
    """ç•°å¸¸ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¦è¿”ã™"""
    try:
        scores = model.decision_function(X)
        logger.info("âœ… ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—å®Œäº†")
        return pd.Series(scores, index=X.index)
    except Exception as e:
        logger.error(f"âŒ ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—å¤±æ•—: {e}")
        return pd.Series()

def plot_anomaly_scores(scores: pd.Series, threshold: Optional[float] = None, title: str = "Anomaly Scores") -> None:
    """ç•°å¸¸ã‚¹ã‚³ã‚¢ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
    try:
        plt.figure(figsize=(10, 5))
        sns.histplot(scores, bins=50, kde=True)
        if threshold is not None:
            plt.axvline(threshold, color='red', linestyle='--', label=f"Threshold = {threshold}")
        plt.title(title)
        plt.xlabel("Anomaly Score")
        plt.ylabel("Frequency")
        plt.legend()
        plt.grid()
        plt.show()
    except Exception as e:
        logger.error(f"âŒ ç•°å¸¸ã‚¹ã‚³ã‚¢ãƒ—ãƒ­ãƒƒãƒˆå¤±æ•—: {e}")
# ================================
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­è¾¼
# ================================

def save_model_to_drive(model: Any, relative_path: str) -> None:
    """ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«ã‚’Google Driveã«ä¿å­˜"""
    try:
        full_path = os.path.join('/content/drive/MyDrive/', relative_path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        joblib.dump(model, full_path)
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {full_path}")
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å¤±æ•—: {e}")

def load_model_from_drive(relative_path: str) -> Any:
    """Google Driveã‹ã‚‰ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
    try:
        full_path = os.path.join('/content/drive/MyDrive/', relative_path)
        return joblib.load(full_path)
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return None
# ================================
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ”¯æ´
# ================================

def upload_file_from_local() -> Dict[str, Any]:
    """ãƒ­ãƒ¼ã‚«ãƒ«PCã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    logger.info("ğŸ“‚ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    uploaded = files.upload()
    logger.info(f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {list(uploaded.keys())}")
    return uploaded