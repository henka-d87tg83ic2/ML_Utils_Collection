# ML_Utils_Collection

## ğŸ”¹ ãƒªãƒã‚¸ãƒˆãƒªæ¦‚è¦
æœ¬ãƒªãƒã‚¸ãƒˆãƒªã¯ã€æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹ä¸»è¦ã‚¿ã‚¹ã‚¯ï¼ˆåˆ†é¡ãƒ»å›å¸°ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ»æ¬¡å…ƒå‰Šæ¸›ãƒ»å¼·åŒ–å­¦ç¿’ãƒ»æ™‚ç³»åˆ—äºˆæ¸¬ãƒ»ç•°å¸¸æ¤œçŸ¥ï¼‰ã«å¯¾å¿œã—ãŸãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ç¾¤ã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚

å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å½¹å‰²ã”ã¨ã«æ•´ç†ã•ã‚Œã¦ãŠã‚Šã€å­¦ç¿’ãƒ»äºˆæ¸¬ãƒ»å¯è¦–åŒ–ãƒ»ä¿å­˜ãƒ»ãƒ­ãƒ¼ãƒ‰ã‚’ç°¡æ½”ã«å®Ÿæ–½ã§ãã¾ã™ã€‚

---

## ğŸ”¹ ä½¿ç”¨æ–¹æ³•ï¼ˆåŸºæœ¬ãƒ•ãƒ­ãƒ¼ï¼‰

1. å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
   ```python
from classification_utils_seiri import train_model, evaluate_model, save_model

# ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ãƒ»å‰å‡¦ç†
from data_utils import load_csv_data, preprocess_and_split
X, y = load_csv_data('path/to/data.csv', target_column='target')

# å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»ä¿å­˜
X_train, X_test, y_train, y_test = preprocess_and_split(X, y)
model = train_model(X_train, y_train)
evaluate_model(model, X_test, y_test)
save_model(model, 'model.pkl')
---
## ğŸ”¹ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã¨ä¸»ãªå½¹å‰²

| ãƒ•ã‚¡ã‚¤ãƒ«å | ä¸»ãªå½¹å‰² |
|:---|:---|
| data_utils.py | ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»å‰å‡¦ç†ãƒ»åˆ†å‰² |
| shap_utils.py | SHAPè§£æãƒ»å¯è¦–åŒ–ãƒ»ä¿å­˜èª­è¾¼ |
| classification_utils_seiri.py | åˆ†é¡ã‚¿ã‚¹ã‚¯ã®å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»ä¿å­˜ |
| regression_utils_seiri.py | å›å¸°ã‚¿ã‚¹ã‚¯ã®å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»ä¿å­˜ |
| clustering_utils_seiri.py | ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»ä¿å­˜ |
| dimensionality_reduction_utils_seiri.py | æ¬¡å…ƒå‰Šæ¸›ï¼ˆPCA/t-SNEï¼‰å­¦ç¿’ãƒ»é©ç”¨ãƒ»ä¿å­˜ |
| reinforcement_learning_utils_seiri.py | å¼·åŒ–å­¦ç¿’ï¼ˆQ-Learningç°¡æ˜“ç‰ˆï¼‰å­¦ç¿’ãƒ»ä¿å­˜ |
| time_series_utils_seiri.py | æ™‚ç³»åˆ—äºˆæ¸¬ï¼ˆARIMAï¼‰å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»ä¿å­˜ |
| anomaly_detection_utils_seiri.py | ç•°å¸¸æ¤œçŸ¥ï¼ˆIsolationForest/OneClassSVMï¼‰å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»ä¿å­˜ |

## å„ãƒ•ã‚¡ã‚¤ãƒ«æ¦‚è¦
- classification_utils.py
- regression_utils.py
- clustering_utils.py
- dimensionality_reduction_utils.py
- reinforcement_learning_utils.py
- time_series_utils.py
- anomaly_detection_utils.py
