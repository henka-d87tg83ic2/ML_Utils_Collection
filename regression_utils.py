# -*- coding: utf-8 -*-
"""regression_utils.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w1D5xR8C1uJLzuoPBgDkX4G7xf7X9YZ_

1. インポート・環境設定（ロギング含む）
2. Google Drive連携・ファイル保存・読込
3. データロード・前処理・分割（ターゲットが連続値）
4. モデル学習（XGBRegressor, RandomForestRegressor, LinearRegression）・ハイパーパラメータチューニング
5. モデル評価（RMSE、MAE、R²）＋グラフ出力
6. SHAP解析（Summary、Waterfall、3D）
7. ファイルアップロード支援
"""

# ================================
# インポートと環境設定
# ================================

import os
import joblib
import logging
import pandas as pd
import numpy as np
import shap
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from google.colab import drive
from google.colab import files

from typing import Any, Dict, List, Optional, Tuple, Union

# ログ設定
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)
# ================================
# Google Drive連携・ファイル保存・読込
# ================================

def mount_drive() -> None:
    """Google Driveをマウントする"""
    try:
        drive.mount('/content/drive')
        logger.info("✅ Google Driveマウント成功")
    except Exception as e:
        logger.error(f"❌ Driveマウント失敗: {e}")

def save_to_drive(data: Any, relative_path: str) -> None:
    """データをGoogle Driveに保存する"""
    try:
        full_path = os.path.join('/content/drive/MyDrive/', relative_path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        joblib.dump(data, full_path)
        logger.info(f"✅ 保存成功: {full_path}")
    except Exception as e:
        logger.error(f"❌ 保存失敗: {e}")

def load_from_drive(relative_path: str) -> Any:
    """Google Driveからデータをロードする"""
    try:
        full_path = os.path.join('/content/drive/MyDrive/', relative_path)
        return joblib.load(full_path)
    except Exception as e:
        logger.error(f"❌ ロード失敗: {e}")
        return None
# ================================
# データロード・前処理・分割
# ================================

def load_csv_data(file_path: str, target_column: str, features_to_drop: Optional[List[str]] = None) -> Tuple[pd.DataFrame, pd.Series]:
    """CSVファイルから回帰用データをロード"""
    try:
        if not os.path.exists(file_path) and '/content/drive' not in file_path:
            file_path = os.path.join('/content/drive/MyDrive/', file_path)

        df = pd.read_csv(file_path)
        logger.info(f"📊 データ概要:\n{df.describe().T}")

        if features_to_drop:
            df = df.drop(columns=features_to_drop)

        if target_column not in df.columns:
            logger.error(f"目的変数 '{target_column}' が存在しません")
            return None, None

        X = df.drop(columns=[target_column])
        y = df[target_column]

        return X, y
    except Exception as e:
        logger.error(f"CSVロード失敗: {e}")
        return None, None

def preprocess_and_split(X: pd.DataFrame, y: pd.Series,
                          test_size: float = 0.2,
                          random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """回帰用データセットを訓練・テストに分割"""
    if X.isnull().sum().sum() > 0:
        logger.info("欠損値を中央値で補完")
        X = X.fillna(X.median())

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
    return X_train, X_test, y_train, y_test
# ================================
# 回帰モデル学習・ハイパーパラメータチューニング
# ================================

def train_regression_model(X_train: pd.DataFrame, y_train: pd.Series,
                            model_type: str = "xgboost",
                            params: Optional[Dict] = None,
                            use_grid_search: bool = False,
                            param_grid: Optional[Dict] = None,
                            cv: int = 5) -> Any:
    """指定された回帰モデルで学習"""
    logger.info(f"🔄 回帰モデル学習開始: {model_type}")

    if model_type.lower() == "xgboost":
        model = XGBRegressor()
    elif model_type.lower() == "random_forest":
        model = RandomForestRegressor()
    elif model_type.lower() == "linear":
        model = LinearRegression()
    else:
        logger.error(f"❌ 未対応の回帰モデルタイプ: {model_type}")
        return None

    if params:
        model.set_params(**params)

    if use_grid_search and param_grid:
        logger.info("🔍 GridSearchCVでハイパーパラチューニング実施")
        model = GridSearchCV(model, param_grid, cv=cv, n_jobs=-1, verbose=1)

    model.fit(X_train, y_train)
    logger.info("✅ モデル学習完了")
    return model

def perform_cross_validation(model: Any, X: pd.DataFrame, y: pd.Series, cv: int = 5) -> Dict[str, float]:
    """回帰モデルのクロスバリデーションスコア計算"""
    logger.info(f"🔄 {cv}-foldクロスバリデーション開始")
    scores = cross_val_score(model, X, y, cv=cv, scoring="neg_root_mean_squared_error")
    return {
        "mean_rmse": -np.mean(scores),
        "std_rmse": np.std(scores)
    }
# ================================
# モデル評価
# ================================

def evaluate_regression_model(model: Any, X_test: pd.DataFrame, y_test: pd.Series,
                               plot_pred_vs_actual: bool = True) -> None:
    """回帰モデルの性能を評価"""
    preds = model.predict(X_test)

    rmse = np.sqrt(mean_squared_error(y_test, preds))
    mae = mean_absolute_error(y_test, preds)
    r2 = r2_score(y_test, preds)

    logger.info(f"📈 RMSE: {rmse:.4f}")
    logger.info(f"📈 MAE: {mae:.4f}")
    logger.info(f"📈 R²: {r2:.4f}")

    if plot_pred_vs_actual:
        plt.scatter(y_test, preds, alpha=0.7)
        plt.xlabel("Actual")
        plt.ylabel("Predicted")
        plt.title("Actual vs Predicted")
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
        plt.show()
# ================================
# SHAP解析
# ================================

def explain_shap(model: Any, X_test: pd.DataFrame,
                 model_type: str = "tree",
                 plot_summary: bool = True, plot_waterfall: bool = True, row_index: int = 0) -> shap.Explanation:
    """回帰モデルのSHAP解析を行う"""
    try:
        if model_type == "tree":
            explainer = shap.TreeExplainer(model)
        else:
            explainer = shap.Explainer(model.predict, X_test)

        shap_values = explainer(X_test)

        if plot_summary:
            shap.summary_plot(shap_values.values, features=X_test, feature_names=X_test.columns)

        if plot_waterfall:
            shap.plots.waterfall(shap_values[row_index])

        return shap_values
    except Exception as e:
        logger.error(f"❌ SHAP解析失敗: {e}")
        return None

def plot_shap_3d(shap_values: shap.Explanation, X_test: pd.DataFrame,
                 feature_x: str, feature_y: str, shap_feature: Optional[str] = None) -> None:
    """2軸特徴量とSHAP値の3Dプロット"""
    try:
        if shap_feature:
            shap_z = shap_values.values[:, X_test.columns.get_loc(shap_feature)]
        else:
            shap_z = shap_values.values.mean(axis=1)

        df = pd.DataFrame({
            "X": X_test[feature_x],
            "Y": X_test[feature_y],
            "SHAP": shap_z
        })

        fig = px.scatter_3d(df, x="X", y="Y", z="SHAP", color="SHAP", opacity=0.7)
        fig.show()
    except Exception as e:
        logger.error(f"❌ 3D SHAPプロット失敗: {e}")
# ================================
# ファイルアップロード支援
# ================================

def upload_file_from_local() -> Dict[str, Any]:
    """ローカルPCからファイルをアップロード"""
    logger.info("📂 ローカルファイルをアップロードしてください")
    uploaded = files.upload()
    logger.info(f"✅ アップロード完了: {list(uploaded.keys())}")
    return uploaded