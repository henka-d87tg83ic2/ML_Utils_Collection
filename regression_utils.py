# -*- coding: utf-8 -*-
"""regression_utils.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w1D5xR8C1uJLzuoPBgDkX4G7xf7X9YZ_

1. ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ»ç’°å¢ƒè¨­å®šï¼ˆãƒ­ã‚®ãƒ³ã‚°å«ã‚€ï¼‰
2. Google Driveé€£æºãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãƒ»èª­è¾¼
3. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»å‰å‡¦ç†ãƒ»åˆ†å‰²ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒé€£ç¶šå€¤ï¼‰
4. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆXGBRegressor, RandomForestRegressor, LinearRegressionï¼‰ãƒ»ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
5. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆRMSEã€MAEã€RÂ²ï¼‰ï¼‹ã‚°ãƒ©ãƒ•å‡ºåŠ›
6. SHAPè§£æï¼ˆSummaryã€Waterfallã€3Dï¼‰
7. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ”¯æ´
"""

# ================================
# ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ç’°å¢ƒè¨­å®š
# ================================

import os
import joblib
import logging
import pandas as pd
import numpy as np
import shap
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from google.colab import drive
from google.colab import files

from typing import Any, Dict, List, Optional, Tuple, Union

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)
# ================================
# Google Driveé€£æºãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãƒ»èª­è¾¼
# ================================

def mount_drive() -> None:
    """Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆã™ã‚‹"""
    try:
        drive.mount('/content/drive')
        logger.info("âœ… Google Driveãƒã‚¦ãƒ³ãƒˆæˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ Driveãƒã‚¦ãƒ³ãƒˆå¤±æ•—: {e}")

def save_to_drive(data: Any, relative_path: str) -> None:
    """ãƒ‡ãƒ¼ã‚¿ã‚’Google Driveã«ä¿å­˜ã™ã‚‹"""
    try:
        full_path = os.path.join('/content/drive/MyDrive/', relative_path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        joblib.dump(data, full_path)
        logger.info(f"âœ… ä¿å­˜æˆåŠŸ: {full_path}")
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜å¤±æ•—: {e}")

def load_from_drive(relative_path: str) -> Any:
    """Google Driveã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    try:
        full_path = os.path.join('/content/drive/MyDrive/', relative_path)
        return joblib.load(full_path)
    except Exception as e:
        logger.error(f"âŒ ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return None
# ================================
# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»å‰å‡¦ç†ãƒ»åˆ†å‰²
# ================================

def load_csv_data(file_path: str, target_column: str, features_to_drop: Optional[List[str]] = None) -> Tuple[pd.DataFrame, pd.Series]:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å›å¸°ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
    try:
        if not os.path.exists(file_path) and '/content/drive' not in file_path:
            file_path = os.path.join('/content/drive/MyDrive/', file_path)

        df = pd.read_csv(file_path)
        logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:\n{df.describe().T}")

        if features_to_drop:
            df = df.drop(columns=features_to_drop)

        if target_column not in df.columns:
            logger.error(f"ç›®çš„å¤‰æ•° '{target_column}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return None, None

        X = df.drop(columns=[target_column])
        y = df[target_column]

        return X, y
    except Exception as e:
        logger.error(f"CSVãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return None, None

def preprocess_and_split(X: pd.DataFrame, y: pd.Series,
                          test_size: float = 0.2,
                          random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """å›å¸°ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆã«åˆ†å‰²"""
    if X.isnull().sum().sum() > 0:
        logger.info("æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œ")
        X = X.fillna(X.median())

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
    return X_train, X_test, y_train, y_test
# ================================
# å›å¸°ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
# ================================

def train_regression_model(X_train: pd.DataFrame, y_train: pd.Series,
                            model_type: str = "xgboost",
                            params: Optional[Dict] = None,
                            use_grid_search: bool = False,
                            param_grid: Optional[Dict] = None,
                            cv: int = 5) -> Any:
    """æŒ‡å®šã•ã‚ŒãŸå›å¸°ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’"""
    logger.info(f"ğŸ”„ å›å¸°ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹: {model_type}")

    if model_type.lower() == "xgboost":
        model = XGBRegressor()
    elif model_type.lower() == "random_forest":
        model = RandomForestRegressor()
    elif model_type.lower() == "linear":
        model = LinearRegression()
    else:
        logger.error(f"âŒ æœªå¯¾å¿œã®å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {model_type}")
        return None

    if params:
        model.set_params(**params)

    if use_grid_search and param_grid:
        logger.info("ğŸ” GridSearchCVã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿæ–½")
        model = GridSearchCV(model, param_grid, cv=cv, n_jobs=-1, verbose=1)

    model.fit(X_train, y_train)
    logger.info("âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
    return model

def perform_cross_validation(model: Any, X: pd.DataFrame, y: pd.Series, cv: int = 5) -> Dict[str, float]:
    """å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢è¨ˆç®—"""
    logger.info(f"ğŸ”„ {cv}-foldã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
    scores = cross_val_score(model, X, y, cv=cv, scoring="neg_root_mean_squared_error")
    return {
        "mean_rmse": -np.mean(scores),
        "std_rmse": np.std(scores)
    }
# ================================
# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
# ================================

def evaluate_regression_model(model: Any, X_test: pd.DataFrame, y_test: pd.Series,
                               plot_pred_vs_actual: bool = True) -> None:
    """å›å¸°ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡"""
    preds = model.predict(X_test)

    rmse = np.sqrt(mean_squared_error(y_test, preds))
    mae = mean_absolute_error(y_test, preds)
    r2 = r2_score(y_test, preds)

    logger.info(f"ğŸ“ˆ RMSE: {rmse:.4f}")
    logger.info(f"ğŸ“ˆ MAE: {mae:.4f}")
    logger.info(f"ğŸ“ˆ RÂ²: {r2:.4f}")

    if plot_pred_vs_actual:
        plt.scatter(y_test, preds, alpha=0.7)
        plt.xlabel("Actual")
        plt.ylabel("Predicted")
        plt.title("Actual vs Predicted")
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
        plt.show()
# ================================
# SHAPè§£æ
# ================================

def explain_shap(model: Any, X_test: pd.DataFrame,
                 model_type: str = "tree",
                 plot_summary: bool = True, plot_waterfall: bool = True, row_index: int = 0) -> shap.Explanation:
    """å›å¸°ãƒ¢ãƒ‡ãƒ«ã®SHAPè§£æã‚’è¡Œã†"""
    try:
        if model_type == "tree":
            explainer = shap.TreeExplainer(model)
        else:
            explainer = shap.Explainer(model.predict, X_test)

        shap_values = explainer(X_test)

        if plot_summary:
            shap.summary_plot(shap_values.values, features=X_test, feature_names=X_test.columns)

        if plot_waterfall:
            shap.plots.waterfall(shap_values[row_index])

        return shap_values
    except Exception as e:
        logger.error(f"âŒ SHAPè§£æå¤±æ•—: {e}")
        return None

def plot_shap_3d(shap_values: shap.Explanation, X_test: pd.DataFrame,
                 feature_x: str, feature_y: str, shap_feature: Optional[str] = None) -> None:
    """2è»¸ç‰¹å¾´é‡ã¨SHAPå€¤ã®3Dãƒ—ãƒ­ãƒƒãƒˆ"""
    try:
        if shap_feature:
            shap_z = shap_values.values[:, X_test.columns.get_loc(shap_feature)]
        else:
            shap_z = shap_values.values.mean(axis=1)

        df = pd.DataFrame({
            "X": X_test[feature_x],
            "Y": X_test[feature_y],
            "SHAP": shap_z
        })

        fig = px.scatter_3d(df, x="X", y="Y", z="SHAP", color="SHAP", opacity=0.7)
        fig.show()
    except Exception as e:
        logger.error(f"âŒ 3D SHAPãƒ—ãƒ­ãƒƒãƒˆå¤±æ•—: {e}")
# ================================
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ”¯æ´
# ================================

def upload_file_from_local() -> Dict[str, Any]:
    """ãƒ­ãƒ¼ã‚«ãƒ«PCã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    logger.info("ğŸ“‚ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    uploaded = files.upload()
    logger.info(f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {list(uploaded.keys())}")
    return uploaded