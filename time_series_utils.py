# -*- coding: utf-8 -*-
"""time_series_utils.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gJAt7L3Xlx03b76fpwUm8v2h5lMrTPqz

1. ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ»ç’°å¢ƒè¨­å®šï¼ˆãƒ­ã‚®ãƒ³ã‚°å«ã‚€ï¼‰
2. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»å‰å‡¦ç†ï¼ˆæ¬ æè£œå®Œãƒ»æ¨™æº–åŒ–ï¼‰
3. ARIMAã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬ï¼ˆstatsmodelsä½¿ç”¨ï¼‰
4. Prophetã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
5. äºˆæ¸¬çµæœã®å¯è¦–åŒ–ï¼ˆå®Ÿæ¸¬ vs äºˆæ¸¬ãƒ—ãƒ­ãƒƒãƒˆï¼‰
6. ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­è¾¼ï¼ˆGoogle Driveå¯¾å¿œï¼‰
7. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ”¯æ´
"""

# ================================
# ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ç’°å¢ƒè¨­å®š
# ================================

import os
import joblib
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.arima.model import ARIMA
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False

from sklearn.preprocessing import StandardScaler
from google.colab import drive
from google.colab import files

from typing import Any, Dict, List, Optional, Tuple, Union

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)
# ================================
# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»å‰å‡¦ç†
# ================================

def load_csv_data(file_path: str, date_column: str, target_column: str) -> pd.DataFrame:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    try:
        if not os.path.exists(file_path) and '/content/drive' not in file_path:
            file_path = os.path.join('/content/drive/MyDrive/', file_path)

        df = pd.read_csv(file_path, parse_dates=[date_column])
        df = df[[date_column, target_column]].dropna()
        df = df.sort_values(by=date_column)
        logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {df.shape}")
        return df
    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return None

def standardize_series(series: pd.Series) -> pd.Series:
    """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ–ã™ã‚‹"""
    try:
        scaler = StandardScaler()
        scaled = scaler.fit_transform(series.values.reshape(-1, 1)).flatten()
        logger.info("âœ… æ¨™æº–åŒ–å®Œäº†")
        return pd.Series(scaled, index=series.index)
    except Exception as e:
        logger.error(f"âŒ æ¨™æº–åŒ–å¤±æ•—: {e}")
        return series
# ================================
# ARIMAã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬
# ================================

def train_arima_model(series: pd.Series, order: Tuple[int, int, int] = (1, 1, 1)) -> Any:
    """ARIMAãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’"""
    try:
        model = ARIMA(series, order=order)
        fitted_model = model.fit()
        logger.info("âœ… ARIMAãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
        return fitted_model
    except Exception as e:
        logger.error(f"âŒ ARIMAå­¦ç¿’å¤±æ•—: {e}")
        return None

def forecast_arima(model: Any, steps: int) -> pd.Series:
    """ARIMAãƒ¢ãƒ‡ãƒ«ã§æœªæ¥äºˆæ¸¬ã‚’è¡Œã†"""
    try:
        forecast = model.forecast(steps=steps)
        logger.info(f"âœ… ARIMAäºˆæ¸¬å®Œäº†: {steps}ã‚¹ãƒ†ãƒƒãƒ—")
        return forecast
    except Exception as e:
        logger.error(f"âŒ ARIMAäºˆæ¸¬å¤±æ•—: {e}")
        return None
# ================================
# Prophetã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬
# ================================

def train_prophet_model(df: pd.DataFrame) -> Optional[Any]:
    """Prophetãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’"""
    if not PROPHET_AVAILABLE:
        logger.error("âŒ ProphetãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None
    try:
        model = Prophet()
        model.fit(df.rename(columns={"ds": "ds", "y": "y"}))
        logger.info("âœ… Prophetãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
        return model
    except Exception as e:
        logger.error(f"âŒ Prophetå­¦ç¿’å¤±æ•—: {e}")
        return None

def forecast_prophet(model: Any, periods: int, freq: str = 'D') -> Optional[pd.DataFrame]:
    """Prophetãƒ¢ãƒ‡ãƒ«ã§æœªæ¥äºˆæ¸¬ã‚’è¡Œã†"""
    try:
        future = model.make_future_dataframe(periods=periods, freq=freq)
        forecast = model.predict(future)
        logger.info(f"âœ… Prophetäºˆæ¸¬å®Œäº†: {periods}æœŸé–“")
        return forecast
    except Exception as e:
        logger.error(f"âŒ Prophetäºˆæ¸¬å¤±æ•—: {e}")
        return None
# ================================
# äºˆæ¸¬çµæœã®å¯è¦–åŒ–
# ================================

def plot_forecast(actual: pd.Series, forecast: pd.Series, title: str = "Forecast vs Actual") -> None:
    """å®Ÿæ¸¬å€¤ã¨äºˆæ¸¬å€¤ã‚’æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ"""
    try:
        plt.figure(figsize=(10, 5))
        plt.plot(actual.index, actual.values, label="Actual", marker='o')
        plt.plot(forecast.index, forecast.values, label="Forecast", marker='x')
        plt.title(title)
        plt.xlabel("Date")
        plt.ylabel("Value")
        plt.legend()
        plt.grid()
        plt.show()
    except Exception as e:
        logger.error(f"âŒ äºˆæ¸¬ãƒ—ãƒ­ãƒƒãƒˆå¤±æ•—: {e}")
# ================================
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­è¾¼
# ================================

def save_model_to_drive(model: Any, relative_path: str) -> None:
    """æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«ã‚’Google Driveã«ä¿å­˜"""
    try:
        full_path = os.path.join('/content/drive/MyDrive/', relative_path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        joblib.dump(model, full_path)
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {full_path}")
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å¤±æ•—: {e}")

def load_model_from_drive(relative_path: str) -> Any:
    """Google Driveã‹ã‚‰æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
    try:
        full_path = os.path.join('/content/drive/MyDrive/', relative_path)
        return joblib.load(full_path)
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return None
# ================================
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ”¯æ´
# ================================

def upload_file_from_local() -> Dict[str, Any]:
    """ãƒ­ãƒ¼ã‚«ãƒ«PCã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    logger.info("ğŸ“‚ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    uploaded = files.upload()
    logger.info(f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {list(uploaded.keys())}")
    return uploaded